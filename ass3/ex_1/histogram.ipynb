{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFtqtoNwC4Zu",
        "outputId": "1642f238-3500-4f58-940d-0899052831b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n",
            "Sun Dec 15 16:00:09 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   52C    P8              12W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile histogram.cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <sys/time.h>\n",
        "#include <random>\n",
        "#include <cuda_runtime.h>\n",
        "#include <fstream>  // For file output\n",
        "#define NUM_BINS 4096\n",
        "#define BIN_MAX 127\n",
        "\n",
        "__global__ void histogram_kernel(unsigned int *input, unsigned int *bins,\n",
        "                                 unsigned int num_elements,\n",
        "                                 unsigned int num_bins) {\n",
        "    // Use shared memory for the histogram bins\n",
        "    extern __shared__ unsigned int shared_bins[];\n",
        "\n",
        "    // Initialize shared memory bins to zero\n",
        "    int tid = threadIdx.x;\n",
        "    for (int i = tid; i < num_bins; i += blockDim.x) {\n",
        "        shared_bins[i] = 0;\n",
        "    }\n",
        "    __syncthreads();\n",
        "\n",
        "    // Compute the histogram using shared memory and atomics\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int stride = blockDim.x * gridDim.x;\n",
        "\n",
        "    while (idx < num_elements) {\n",
        "        atomicAdd(&shared_bins[input[idx]], 1);\n",
        "        idx += stride;\n",
        "     }\n",
        "\n",
        "    __syncthreads();\n",
        "\n",
        "    // Merge shared memory bins into global memory bins using atomics\n",
        "    for (int i = tid; i < num_bins; i += blockDim.x) {\n",
        "        atomicAdd(&bins[i], shared_bins[i]);\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void convert_kernel(unsigned int *bins, unsigned int num_bins) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int stride = blockDim.x * gridDim.x;\n",
        "\n",
        "    while (idx < num_bins) {\n",
        "        if (bins[idx] > BIN_MAX) {\n",
        "            bins[idx] = BIN_MAX;\n",
        "        }\n",
        "        idx += stride;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main(int argc, char **argv) {\n",
        "    if (argc != 2) {\n",
        "        printf(\"Usage: %s <inputLength>\\n\", argv[0]);\n",
        "        return 1;\n",
        "    }\n",
        "\n",
        "    int inputLength = atoi(argv[1]);\n",
        "    printf(\"The input length is %d\\n\", inputLength);\n",
        "\n",
        "    unsigned int *hostInput, *hostBins, *resultRef;\n",
        "    unsigned int *deviceInput, *deviceBins;\n",
        "\n",
        "    // Allocate Host memory for input and output\n",
        "    hostInput = (unsigned int *)malloc(inputLength * sizeof(unsigned int));\n",
        "    hostBins = (unsigned int *)malloc(NUM_BINS * sizeof(unsigned int));\n",
        "    resultRef = (unsigned int *)malloc(NUM_BINS * sizeof(unsigned int));\n",
        "\n",
        "    // Initialize hostInput to random numbers whose values range from 0 to (NUM_BINS - 1)\n",
        "    std::random_device rd;\n",
        "    std::mt19937 gen(rd());\n",
        "    std::uniform_int_distribution<> dis(0, NUM_BINS - 1);\n",
        "    for (int i = 0; i < inputLength; ++i) {\n",
        "        hostInput[i] = dis(gen);\n",
        "    }\n",
        "\n",
        "    // Create reference result in CPU\n",
        "    for (int i = 0; i < NUM_BINS; ++i) {\n",
        "        resultRef[i] = 0;\n",
        "    }\n",
        "    for (int i = 0; i < inputLength; ++i) {\n",
        "        if (resultRef[hostInput[i]] < BIN_MAX) {\n",
        "            resultRef[hostInput[i]]++;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // Allocate GPU memory\n",
        "    cudaMalloc(&deviceInput, inputLength * sizeof(unsigned int));\n",
        "    cudaMalloc(&deviceBins, NUM_BINS * sizeof(unsigned int));\n",
        "\n",
        "    // Copy memory to the GPU\n",
        "    cudaMemcpy(deviceInput, hostInput, inputLength * sizeof(unsigned int), cudaMemcpyHostToDevice);\n",
        "    cudaMemset(deviceBins, 0, NUM_BINS * sizeof(unsigned int));\n",
        "\n",
        "    // Initialize grid and block dimensions\n",
        "    int threadsPerBlock = 256;\n",
        "    int blocksPerGrid = (inputLength + threadsPerBlock - 1) / threadsPerBlock;\n",
        "\n",
        "    // Launch the histogram kernel\n",
        "    size_t sharedMemSize = NUM_BINS * sizeof(unsigned int);\n",
        "    histogram_kernel<<<blocksPerGrid, threadsPerBlock, sharedMemSize>>>(deviceInput, deviceBins, inputLength, NUM_BINS);\n",
        "\n",
        "    // Launch the cleanup kernel\n",
        "    blocksPerGrid = (NUM_BINS + threadsPerBlock - 1) / threadsPerBlock;\n",
        "    convert_kernel<<<blocksPerGrid, threadsPerBlock>>>(deviceBins, NUM_BINS);\n",
        "\n",
        "    // Copy the GPU memory back to the CPU\n",
        "    cudaMemcpy(hostBins, deviceBins, NUM_BINS * sizeof(unsigned int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Compare the output with the reference\n",
        "    bool match = true;\n",
        "    for (int i = 0; i < NUM_BINS; ++i) {\n",
        "        if (hostBins[i] != resultRef[i]) {\n",
        "            printf(\"Mismatch at bin %d: GPU %d, CPU %d\\n\", i, hostBins[i], resultRef[i]);\n",
        "            match = false;\n",
        "            break;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    if (match) {\n",
        "        printf(\"Results match!\\n\");\n",
        "    } else {\n",
        "        printf(\"Results do not match!\\n\");\n",
        "    }\n",
        "\n",
        "\n",
        "    // Save hostBins to a file\n",
        "    printf(\"Saving histogram...\\n\");\n",
        "    std::ofstream outfile(\"histogram_data.txt\");\n",
        "    for (int i = 0; i < NUM_BINS; ++i) {\n",
        "        outfile << hostBins[i] << std::endl;\n",
        "    }\n",
        "    outfile.close();\n",
        "\n",
        "    // Free the GPU memory\n",
        "    cudaFree(deviceInput);\n",
        "    cudaFree(deviceBins);\n",
        "\n",
        "    // Free the CPU memory\n",
        "    free(hostInput);\n",
        "    free(hostBins);\n",
        "    free(resultRef);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5uulIty6C586",
        "outputId": "6e78b53e-d4d5-4378-a684-c3acbe8511ab"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting histogram.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc histogram.cu -o histogram_exec\n",
        "!./histogram_exec 1024"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTH6d2PoC7u3",
        "outputId": "c5349765-5eb0-4ca0-eafb-8fc3f5d84162"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The input length is 1024\n",
            "Results match!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# /content/histogram_data.txt\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Read histogram data from the uploaded file\n",
        "data = np.loadtxt(\"histogram_data.txt\", dtype=int)\n",
        "\n",
        "# Step 2: Define bins and plot the histogram\n",
        "bins = np.arange(len(data))\n",
        "plt.bar(bins, data, color='blue')\n",
        "\n",
        "# Step 3: Customize and display the plot\n",
        "plt.title(\"Histogram\")\n",
        "plt.xlabel(\"Bin Index\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "-QEjoryrECiE",
        "outputId": "7a9c57eb-c71e-4bcc-c355-56ae3a011e05"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile histogram_nsight.cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <sys/time.h>\n",
        "#include <random>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "#define NUM_BINS 4096\n",
        "#define BIN_MAX 127\n",
        "\n",
        "__global__ void histogram_kernel(unsigned int *input, unsigned int *bins,\n",
        "                                 unsigned int num_elements,\n",
        "                                 unsigned int num_bins) {\n",
        "    // Use shared memory for the histogram bins\n",
        "    extern __shared__ unsigned int shared_bins[];\n",
        "\n",
        "    // Initialize shared memory bins to zero\n",
        "    int tid = threadIdx.x;\n",
        "    for (int i = tid; i < num_bins; i += blockDim.x) {\n",
        "        shared_bins[i] = 0;\n",
        "    }\n",
        "    __syncthreads();\n",
        "\n",
        "    // Compute the histogram using shared memory and atomics\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int stride = blockDim.x * gridDim.x;\n",
        "\n",
        "    while (idx < num_elements) {\n",
        "        atomicAdd(&shared_bins[input[idx]], 1);\n",
        "        idx += stride;\n",
        "     }\n",
        "\n",
        "    __syncthreads();\n",
        "\n",
        "    // Merge shared memory bins into global memory bins using atomics\n",
        "    for (int i = tid; i < num_bins; i += blockDim.x) {\n",
        "        atomicAdd(&bins[i], shared_bins[i]);\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void convert_kernel(unsigned int *bins, unsigned int num_bins) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int stride = blockDim.x * gridDim.x;\n",
        "\n",
        "    while (idx < num_bins) {\n",
        "        if (bins[idx] > BIN_MAX) {\n",
        "            bins[idx] = BIN_MAX;\n",
        "        }\n",
        "        idx += stride;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main(int argc, char **argv) {\n",
        "    int inputLength = 1024000;\n",
        "    printf(\"The input length is %d\\n\", inputLength);\n",
        "\n",
        "    unsigned int *hostInput, *hostBins, *resultRef;\n",
        "    unsigned int *deviceInput, *deviceBins;\n",
        "\n",
        "    // Allocate Host memory for input and output\n",
        "    hostInput = (unsigned int *)malloc(inputLength * sizeof(unsigned int));\n",
        "    hostBins = (unsigned int *)malloc(NUM_BINS * sizeof(unsigned int));\n",
        "    resultRef = (unsigned int *)malloc(NUM_BINS * sizeof(unsigned int));\n",
        "\n",
        "    // Initialize hostInput to random numbers whose values range from 0 to (NUM_BINS - 1)\n",
        "    std::random_device rd;\n",
        "    std::mt19937 gen(rd());\n",
        "    std::uniform_int_distribution<> dis(0, NUM_BINS - 1);\n",
        "    for (int i = 0; i < inputLength; ++i) {\n",
        "        hostInput[i] = dis(gen);\n",
        "    }\n",
        "\n",
        "    // Create reference result in CPU\n",
        "    for (int i = 0; i < NUM_BINS; ++i) {\n",
        "        resultRef[i] = 0;\n",
        "    }\n",
        "    for (int i = 0; i < inputLength; ++i) {\n",
        "        if (resultRef[hostInput[i]] < BIN_MAX) {\n",
        "            resultRef[hostInput[i]]++;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // Allocate GPU memory\n",
        "    cudaMalloc(&deviceInput, inputLength * sizeof(unsigned int));\n",
        "    cudaMalloc(&deviceBins, NUM_BINS * sizeof(unsigned int));\n",
        "\n",
        "    // Copy memory to the GPU\n",
        "    cudaMemcpy(deviceInput, hostInput, inputLength * sizeof(unsigned int), cudaMemcpyHostToDevice);\n",
        "    cudaMemset(deviceBins, 0, NUM_BINS * sizeof(unsigned int));\n",
        "\n",
        "    // Initialize grid and block dimensions\n",
        "    int threadsPerBlock = 256;\n",
        "    int blocksPerGrid = (inputLength + threadsPerBlock - 1) / threadsPerBlock;\n",
        "\n",
        "    // Launch the histogram kernel\n",
        "    size_t sharedMemSize = NUM_BINS * sizeof(unsigned int);\n",
        "    histogram_kernel<<<blocksPerGrid, threadsPerBlock, sharedMemSize>>>(deviceInput, deviceBins, inputLength, NUM_BINS);\n",
        "\n",
        "    // Launch the cleanup kernel\n",
        "    blocksPerGrid = (NUM_BINS + threadsPerBlock - 1) / threadsPerBlock;\n",
        "    convert_kernel<<<blocksPerGrid, threadsPerBlock>>>(deviceBins, NUM_BINS);\n",
        "\n",
        "    // Copy the GPU memory back to the CPU\n",
        "    cudaMemcpy(hostBins, deviceBins, NUM_BINS * sizeof(unsigned int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Compare the output with the reference\n",
        "    bool match = true;\n",
        "    for (int i = 0; i < NUM_BINS; ++i) {\n",
        "        if (hostBins[i] != resultRef[i]) {\n",
        "            printf(\"Mismatch at bin %d: GPU %d, CPU %d\\n\", i, hostBins[i], resultRef[i]);\n",
        "            match = false;\n",
        "            break;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    if (match) {\n",
        "        printf(\"Results match!\\n\");\n",
        "    } else {\n",
        "        printf(\"Results do not match!\\n\");\n",
        "    }\n",
        "\n",
        "    // Free the GPU memory\n",
        "    cudaFree(deviceInput);\n",
        "    cudaFree(deviceBins);\n",
        "\n",
        "    // Free the CPU memory\n",
        "    free(hostInput);\n",
        "    free(hostBins);\n",
        "    free(resultRef);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A465BB7OC_Qa",
        "outputId": "cecaf470-087d-48d4-a30a-4409e21e37ca"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting histogram_nsight.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc histogram_nsight.cu -o histogram_exec_nsight\n",
        "!ncu ./histogram_exec_nsight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JrWIzSaNDK61",
        "outputId": "402a2fb2-9870-47c3-96d1-3f2adc569259"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The input length is 1024000\n",
            "==PROF== Connected to process 8322 (/content/histogram_exec_nsight)\n",
            "==PROF== Profiling \"histogram_kernel\" - 0: 0%....50%....100% - 8 passes\n",
            "==PROF== Profiling \"convert_kernel\" - 1: 0%....50%....100% - 8 passes\n",
            "Results match!\n",
            "==PROF== Disconnected from process 8322\n",
            "[8322] histogram_exec_nsight@127.0.0.1\n",
            "  histogram_kernel(unsigned int *, unsigned int *, unsigned int, unsigned int) (4000, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ------------- ------------\n",
            "    Metric Name               Metric Unit Metric Value\n",
            "    ----------------------- ------------- ------------\n",
            "    DRAM Frequency          cycle/nsecond         4.98\n",
            "    SM Frequency            cycle/usecond       583.92\n",
            "    Elapsed Cycles                  cycle      135,196\n",
            "    Memory Throughput                   %        60.36\n",
            "    DRAM Throughput                     %         7.46\n",
            "    Duration                      usecond       231.52\n",
            "    L1/TEX Cache Throughput             %        95.51\n",
            "    L2 Cache Throughput                 %        40.94\n",
            "    SM Active Cycles                cycle   133,458.65\n",
            "    Compute (SM) Throughput             %        60.36\n",
            "    ----------------------- ------------- ------------\n",
            "\n",
            "    INF   Compute and Memory are well-balanced: To reduce runtime, both computation and memory traffic must be reduced. \n",
            "          Check both the Compute Workload Analysis and Memory Workload Analysis sections.                               \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                                  4,000\n",
            "    Registers Per Thread             register/thread              16\n",
            "    Shared Memory Configuration Size           Kbyte           65.54\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block      Kbyte/block           16.38\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    Threads                                   thread       1,024,000\n",
            "    Waves Per SM                                                  25\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block           16\n",
            "    Block Limit Shared Mem                block            4\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        93.22\n",
            "    Achieved Active Warps Per SM           warp        29.83\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    INF   This kernel's theoretical occupancy is not impacted by any block limit.                                       \n",
            "\n",
            "  convert_kernel(unsigned int *, unsigned int) (16, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ------------- ------------\n",
            "    Metric Name               Metric Unit Metric Value\n",
            "    ----------------------- ------------- ------------\n",
            "    DRAM Frequency          cycle/nsecond         4.71\n",
            "    SM Frequency            cycle/usecond       547.74\n",
            "    Elapsed Cycles                  cycle        2,086\n",
            "    Memory Throughput                   %         1.70\n",
            "    DRAM Throughput                     %         1.70\n",
            "    Duration                      usecond         3.81\n",
            "    L1/TEX Cache Throughput             %         5.19\n",
            "    L2 Cache Throughput                 %         1.47\n",
            "    SM Active Cycles                cycle       369.62\n",
            "    Compute (SM) Throughput             %         0.92\n",
            "    ----------------------- ------------- ------------\n",
            "\n",
            "    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      \n",
            "          waves across all SMs. Look at Launch Statistics for more details.                                             \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                                     16\n",
            "    Registers Per Thread             register/thread              16\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    Threads                                   thread           4,096\n",
            "    Waves Per SM                                                0.10\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    OPT   Estimated Speedup: 60%                                                                                        \n",
            "          The grid for this launch is configured to execute only 16 blocks, which is less than the GPU's 40             \n",
            "          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      \n",
            "          concurrently with other workloads, consider reducing the block size to have at least one block per            \n",
            "          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    \n",
            "          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            \n",
            "          description for more details on launch configurations.                                                        \n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block           16\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        24.45\n",
            "    Achieved Active Warps Per SM           warp         7.82\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    OPT   Estimated Speedup: 75.55%                                                                                     \n",
            "          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     \n",
            "          theoretical (100.0%) and measured achieved occupancy (24.5%) can be the result of warp scheduling overheads   \n",
            "          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    \n",
            "          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                \n",
            "          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           \n",
            "          optimizing occupancy.                                                                                         \n",
            "\n"
          ]
        }
      ]
    }
  ]
}